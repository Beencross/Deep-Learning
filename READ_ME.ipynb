{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "READ_ME.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq14Rk-vOF9_"
      },
      "source": [
        "### **Competition Name** : Recursion Cellular Image Classification Cell Signal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0lA2McVPVZ4"
      },
      "source": [
        "# **Competition Objective :** \n",
        "\n",
        "The main goal is to understand how drugs interact with human cells, including  improve the industryâ€™s ability to model cellular images according to their relevant biology. \n",
        "\n",
        "This AI application could greatly decrease the cost of treatments, and ensure these treatments get to patients faster.\n",
        "it is necessary to eliminate  the noise introduced by technical execution and environmental variation between experiments.\n",
        "\n",
        "This dataset challenges to develop a model for identifying replicates that is robust to experimental noise.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ia_X_iPaAKW"
      },
      "source": [
        "# **Data Source :**\n",
        "\n",
        "The Recursion Cellular Image Classification competition classify images of cells in the RxRx1 dataset, which consists of 125,510 six-channel fluorescent microscopy images of cells across 1,108 different genetic perturbations in four different cell lines. Importantly, RxRx1 was generated in 51 different batches, or repeats of the same experimental design, and competitors were given the images from 33 of these batches for training their models, while the images from the other 18 batches were held out for testing those models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwTLTBlmbLO0"
      },
      "source": [
        "## Data pre-processing & augmentation : \n",
        "\n",
        "\n",
        "\n",
        "*   Loading original images (512x512)\n",
        "\n",
        "*   HUVEC-18 is moved to the training set (known leak)\n",
        "\n",
        "*   For training, all control images (also these from the test set) are used in the same way as non-control images\n",
        "\n",
        "\n",
        "*   Normalizing each image channel to N(0, 1)\n",
        "\n",
        "*   Random horizontal and vertical flip, and 90 degrees rotation\n",
        "\n",
        "*   Random resized crop preserving aspect with scale ~ uniform(0.5, 1) using nearest-neighbor interpolation\n",
        "\n",
        "*   Training augmentations\n",
        "\n",
        "\n",
        "*   For each channel: channel = channel * a + b, where a ~ N(1, 0.1), b ~ N(0, 0.1)\n",
        "\n",
        "*   Test-time augmentations\n",
        "\n",
        "*   Horizontal and vertical flip, and 90 degrees rotation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C2KMG8xlh4b"
      },
      "source": [
        "## **Training** : \n",
        "\n",
        "Batch size: 24 (48 with gradient accumulation)\n",
        "\n",
        "*   Batch size: 24 (48 with gradient accumulation)\n",
        "\n",
        "*   Optimizer: Adam\n",
        "\n",
        "*   Weight decay: 1e-5\n",
        "\n",
        "*   Cutmix\n",
        "\n",
        "\n",
        "*   Loss = ArcFaceLoss / 2 * 0.2 + SoftmaxCrossEntropyLoss * 0.8\n",
        "(ArcFaceLoss is divided by 2 to more or less preserve magnitude between losses)\n",
        "\n",
        "\n",
        "*   90 epochs\n",
        "\n",
        "*   Learning rate: 1.5e-4 with cosine scheduling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7yvBI_2mSsC"
      },
      "source": [
        "# **Difficulties :**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gVMUvjsl-2d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}